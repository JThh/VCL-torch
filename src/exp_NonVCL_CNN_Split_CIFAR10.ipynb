{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84cb1cd5-cf90-403c-ad65-3f638f3ef83c",
   "metadata": {},
   "source": [
    "# Experiment with CNN via Various Non-VCL Approaches (e.g. MAP, LP, EWC, SI) on Split-CIFAR10 Task\n",
    "\n",
    "The models are configured in almost the same way (in terms of widths and depths) as in the VCL experiments, namely CNN-4 and ResNet-4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d0b355-b9e1-49e8-8bc5-8e5cdc2be70c",
   "metadata": {},
   "source": [
    "## Model Definition and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f67058a-272b-4204-9fc4-81c28984e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d61dc52-73d3-40e1-8302-c95be5e115ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define non-vcl CNN & ResNet with task heads \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_tasks=5, num_classes_per_task=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.shared_conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.fc_input_dim = 256 * 4 * 4  \n",
    "        \n",
    "        self.task_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.fc_input_dim, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, num_classes_per_task)\n",
    "            ) for _ in range(num_tasks)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, task_idx):\n",
    "        x = self.shared_conv_layers(x)\n",
    "        x = x.view(-1, self.fc_input_dim)  # Flatten\n",
    "        task_output = self.task_heads[task_idx](x)\n",
    "        return F.log_softmax(task_output, dim=1)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetCIFAR10(nn.Module):\n",
    "    def __init__(self, block=BasicBlock, num_blocks=[2, 2], num_tasks=5, num_classes_per_task=100, in_channels=3):\n",
    "        super(ResNetCIFAR10, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "\n",
    "        self.task_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(8192 * block.expansion, num_classes_per_task)\n",
    "            ) for _ in range(num_tasks)\n",
    "        ])\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, task_idx):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        task_output = self.task_heads[task_idx](out)\n",
    "        return F.log_softmax(task_output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f039d78-1220-4b1f-9ca3-7fc4f3d49693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get split CIFAR10 dataset\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "from util.transforms import Flatten, Scale\n",
    "\n",
    "# Normalization for CIFAR10\n",
    "normalize = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "# permutation used for each task (add flatten for mlp)\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "# transform = Compose([Flatten(), Scale()])\n",
    "\n",
    "cifar_train = CIFAR10(root=f\"/scratch-ssd/oatml/data\", train=True, download=False, transform=transform)\n",
    "cifar_test = CIFAR10(root=f\"/scratch-ssd/oatml/data\", train=False, download=False, transform=transform)\n",
    "\n",
    "label_to_task_mapping = {\n",
    "    0: 0, 1: 0,\n",
    "    2: 1, 3: 1,\n",
    "    4: 2, 5: 2,\n",
    "    6: 3, 7: 3,\n",
    "    8: 4, 9: 4,\n",
    "}\n",
    "\n",
    "if isinstance(cifar_train[0][1], int):\n",
    "    train_task_ids = torch.Tensor([label_to_task_mapping[y] for _, y in cifar_train])\n",
    "    test_task_ids = torch.Tensor([label_to_task_mapping[y] for _, y in cifar_test])\n",
    "elif isinstance(cifar_train[0][1], torch.Tensor):\n",
    "    train_task_ids = torch.Tensor([label_to_task_mapping[y.item()] for _, y in cifar_train])\n",
    "    test_task_ids = torch.Tensor([label_to_task_mapping[y.item()] for _, y in cifar_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3befbd0-52d4-45e9-a610-62907604f1b5",
   "metadata": {},
   "source": [
    "## Joint Accuracy (Upperbounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "937dadbe-e68e-495b-8cf5-e468e664e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on Split CIFAR10 with new model instantiated at each run\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from util.operations import task_subset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "binarize_y = lambda y, task: (y == (2 * task + 1)).long()\n",
    "\n",
    "def test_model(model, dataloader, device, task_idx):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(device), binarize_y(data[1], task_idx).to(device)\n",
    "            outputs = model(images, 0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_cifar_split(cls, log_name, cifar_train, cifar_test, train_task_ids, test_task_ids, device):\n",
    "    \"\"\"\n",
    "    Trains separate models on a split CIFAR10 dataset (five binary tasks).\n",
    "\n",
    "    Args:\n",
    "    - cls: The model constructor to train with.\n",
    "    - log_name: Name for the TensorBoard logs.\n",
    "    - cifar_train: Training dataset.\n",
    "    - cifar_test: Test dataset.\n",
    "    - train_task_ids: Task IDs for the training data.\n",
    "    - test_task_ids: Task IDs for the test data.\n",
    "    - device: Torch device to use for training.\n",
    "    \"\"\"\n",
    "    # Setup TensorBoard writer\n",
    "    summary_logdir = os.path.join(\"logs\", log_name, datetime.now().strftime('%b%d_%H-%M-%S'))\n",
    "    summary_writer = SummaryWriter(summary_logdir)\n",
    "    experiment_path = f\"out/experiments/{log_name}\"\n",
    "    os.makedirs(experiment_path, exist_ok=True)  # Ensure output directory exists\n",
    "    accuracies = {}\n",
    "\n",
    "    num_tasks = 5\n",
    "    for task_idx in range(num_tasks):\n",
    "        print(f\"Training on task {task_idx}\")\n",
    "        model = cls(in_channels=3, num_tasks=1, num_classes_per_task=2).to(device)\n",
    "        \n",
    "        task_dataset = task_subset(cifar_train, train_task_ids, task_idx)\n",
    "        task_dataloader = DataLoader(task_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "        test_dataset = task_subset(cifar_test, test_task_ids, task_idx)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in tqdm(range(100), desc=f\"Epoch: \"):\n",
    "            for images, labels in task_dataloader:\n",
    "                images, labels = images.to(device), binarize_y(labels, task_idx).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images, 0)\n",
    "                loss = F.nll_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            summary_writer.add_scalar(f'Task_{task_idx}/Train_Loss', loss.item(), epoch)\n",
    "\n",
    "        task_accuracy = test_model(model, test_dataloader, device, task_idx)\n",
    "        print(f\"Test accuracy on task {task_idx}: {task_accuracy}%\")\n",
    "        summary_writer.add_scalar(f\"Accuracy/task_{task_idx}_max\", task_accuracy, global_step=task_idx)\n",
    "        accuracies[f\"TASK {task_idx}\"] = task_accuracy\n",
    "\n",
    "    # Save accuracies to file\n",
    "    accuracies_file = os.path.join(experiment_path, \"final_accuracies.json\")\n",
    "    with open(accuracies_file, 'w') as f:\n",
    "        json.dump(accuracies, f)\n",
    "    print(f\"Accuracies saved to {accuracies_file}\")\n",
    "\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a09d7eb0-b179-4119-b3c7-936fb5b69c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a953d5f54e946b99e5a6d27de019034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 96.15%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5effb3b950e24b07add53a2515b88ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 86.4%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7af00ddc8744e2488e24e1fe6092b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 91.8%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc21abbff2734d9ea28cf89f7745bbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 3: 96.8%\n",
      "Training on task 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a23042821ce4820ad0b2ad00aa47639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 4: 96.0%\n",
      "Accuracies saved to out/experiments/joint_disc_conv_s_cifar10_upperbound/final_accuracies.json\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'writer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_cifar_split(\n\u001b[1;32m      2\u001b[0m     CNN, \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoint_disc_conv_s_cifar10_upperbound\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m     cifar_train, \n\u001b[1;32m      5\u001b[0m     cifar_test, \n\u001b[1;32m      6\u001b[0m     train_task_ids, \n\u001b[1;32m      7\u001b[0m     test_task_ids, \n\u001b[1;32m      8\u001b[0m     device\n\u001b[1;32m      9\u001b[0m )\n",
      "Cell \u001b[0;32mIn[13], line 89\u001b[0m, in \u001b[0;36mtrain_cifar_split\u001b[0;34m(cls, log_name, cifar_train, cifar_test, train_task_ids, test_task_ids, device)\u001b[0m\n\u001b[1;32m     86\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(accuracies, f)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracies saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracies_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'writer' is not defined"
     ]
    }
   ],
   "source": [
    "train_cifar_split(\n",
    "    CNN, \n",
    "    \"joint_disc_conv_s_cifar10_upperbound\", \n",
    "    cifar_train, \n",
    "    cifar_test, \n",
    "    train_task_ids, \n",
    "    test_task_ids, \n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b107042-e09e-4a3f-b427-264ffbd72332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f82cb93af864c04804bb63a8fbbed1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 97.95%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5701cfcd50934071b3353d1d3928d29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 88.35%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b5e7d6d0914a7394bcb442cde4d440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 93.55%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909becd2423e41a6906990e31b2a5823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 3: 97.7%\n",
      "Training on task 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d39faee873149fd9c6ef4f911b1919c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 4: 91.75%\n",
      "Accuracies saved to out/experiments/joint_disc_resnet_s_cifar10_upperbound/final_accuracies.json\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'writer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_cifar_split(\n\u001b[1;32m      2\u001b[0m     ResNetCIFAR10, \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoint_disc_resnet_s_cifar10_upperbound\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      4\u001b[0m     cifar_train, \n\u001b[1;32m      5\u001b[0m     cifar_test, \n\u001b[1;32m      6\u001b[0m     train_task_ids, \n\u001b[1;32m      7\u001b[0m     test_task_ids, \n\u001b[1;32m      8\u001b[0m     device\n\u001b[1;32m      9\u001b[0m )\n",
      "Cell \u001b[0;32mIn[13], line 89\u001b[0m, in \u001b[0;36mtrain_cifar_split\u001b[0;34m(cls, log_name, cifar_train, cifar_test, train_task_ids, test_task_ids, device)\u001b[0m\n\u001b[1;32m     86\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(accuracies, f)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracies saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracies_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'writer' is not defined"
     ]
    }
   ],
   "source": [
    "train_cifar_split(\n",
    "    ResNetCIFAR10, \n",
    "    \"joint_disc_resnet_s_cifar10_upperbound\", \n",
    "    cifar_train, \n",
    "    cifar_test, \n",
    "    train_task_ids, \n",
    "    test_task_ids, \n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deddf21-5060-49f4-8e15-25e7045809a4",
   "metadata": {},
   "source": [
    "## MLE / MAP for Split CIFAR10 with CNN/ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "509622fa-e9e9-4a7b-8940-c378b9c05cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on Split CIFAR10 without any CL strategies.\n",
    "def test_model(model, dataloader, device, task_idx):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(device), binarize_y(data[1], task_idx).to(device)\n",
    "            outputs = model(images, task_idx)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_cifar_split(model, log_name, cifar_train, cifar_test, train_task_ids, test_task_ids, device):\n",
    "    \"\"\"\n",
    "    Trains a given model on a split CIFAR10 dataset without continual learning strategies.\n",
    "\n",
    "    Args:\n",
    "    - model: The model to train.\n",
    "    - log_name: Name for the TensorBoard logs.\n",
    "    - cifar_train: Training dataset.\n",
    "    - cifar_test: Test dataset.\n",
    "    - train_task_ids: Task IDs for the training data.\n",
    "    - test_task_ids: Task IDs for the test data.\n",
    "    - device: Torch device to use for training.\n",
    "    \"\"\"\n",
    "    # Setup TensorBoard writer\n",
    "    summary_logdir = os.path.join(\"logs\", log_name, datetime.now().strftime('%b%d_%H-%M-%S'))\n",
    "    summary_writer = SummaryWriter(summary_logdir)\n",
    "    os.makedirs(\"out/models/\", exist_ok=True)  # Ensure output directory exists\n",
    "    experiment_path = f\"out/experiments/{log_name}\"\n",
    "    os.makedirs(experiment_path, exist_ok=True)  # Ensure output directory exists\n",
    "    accuracies = {}\n",
    "\n",
    "    num_tasks = 5\n",
    "    for task_idx in range(num_tasks):\n",
    "        print(f\"Training on task {task_idx}\")\n",
    "        task_dataset = task_subset(cifar_train, train_task_ids, task_idx)\n",
    "        task_dataloader = DataLoader(task_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "        test_dataset = task_subset(cifar_test, test_task_ids, task_idx)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in tqdm(range(100), desc=f\"Epoch: \"):\n",
    "            for images, labels in task_dataloader:\n",
    "                images, labels = images.to(device), binarize_y(labels, task_idx).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images, task_idx)\n",
    "                loss = F.nll_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            summary_writer.add_scalar(f'Task_{task_idx}/Train_Loss', loss.item(), epoch)\n",
    "\n",
    "        task_accuracy = test_model(model, test_dataloader, device, task_idx)\n",
    "        print(f\"Test accuracy on task {task_idx}: {task_accuracy}%\")\n",
    "        summary_writer.add_scalar(f\"Accuracy/task_{task_idx}\", task_accuracy, global_step=task_idx)\n",
    "        accuracies[f\"TASK {task_idx}\"] = task_accuracy\n",
    "\n",
    "        for previous_task_idx in range(task_idx + 1):\n",
    "            test_dataset = task_subset(cifar_test, test_task_ids, previous_task_idx)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "            \n",
    "            accuracy = test_model(model, test_dataloader, device, previous_task_idx)\n",
    "            print(f\"Test accuracy on previous task {previous_task_idx}: {accuracy}%\")\n",
    "            summary_writer.add_scalar(f\"Cross_Task_Accuracy/task_{task_idx}_on_{previous_task_idx}\", accuracy, global_step=task_idx)\n",
    "            accuracies[f\"TASK {previous_task_idx}\"] = accuracy\n",
    "            \n",
    "    # Save model state\n",
    "    model_save_path = os.path.join(\"out/models/\", f\"{log_name}_model_final.pth\")\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # Save accuracies to file\n",
    "    accuracies_file = os.path.join(experiment_path, \"final_accuracies.json\")\n",
    "    with open(accuracies_file, 'w') as f:\n",
    "        json.dump(accuracies, f)\n",
    "    print(f\"Accuracies saved to {accuracies_file}\")\n",
    "\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7266e938-9958-42b4-af64-0a2a6d134c2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91cbb8916d7442095a0681865872731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 97.4%\n",
      "Test accuracy on previous task 0: 97.4%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057fed13be814a8fa05783dd8ae75478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 88.5%\n",
      "Test accuracy on previous task 0: 84.9%\n",
      "Test accuracy on previous task 1: 88.5%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc144e7c9264852ad9e620e72a6c45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 93.8%\n",
      "Test accuracy on previous task 0: 77.7%\n",
      "Test accuracy on previous task 1: 80.8%\n",
      "Test accuracy on previous task 2: 93.8%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657d3a95c9c84b0591a5e6dcb960b390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 3: 98.2%\n",
      "Test accuracy on previous task 0: 58.5%\n",
      "Test accuracy on previous task 1: 71.9%\n",
      "Test accuracy on previous task 2: 86.95%\n",
      "Test accuracy on previous task 3: 98.2%\n",
      "Training on task 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d15c74dfcc490d8eac230a341ef986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 4: 97.55%\n",
      "Test accuracy on previous task 0: 64.85%\n",
      "Test accuracy on previous task 1: 65.55%\n",
      "Test accuracy on previous task 2: 72.2%\n",
      "Test accuracy on previous task 3: 83.95%\n",
      "Test accuracy on previous task 4: 97.55%\n",
      "Model saved to out/models/mle_disc_resnet_s_cifar10_model_final.pth\n",
      "Accuracies saved to out/experiments/mle_disc_resnet_s_cifar10/final_accuracies.json\n"
     ]
    }
   ],
   "source": [
    "model = ResNetCIFAR10(in_channels=3, num_tasks=5, num_classes_per_task=2).to(device)\n",
    "train_cifar_split(\n",
    "    model, \n",
    "    \"mle_disc_resnet_s_cifar10\", \n",
    "    cifar_train, \n",
    "    cifar_test, \n",
    "    train_task_ids, \n",
    "    test_task_ids, \n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65a82f09-9d57-432b-9326-d8b5a6bfcc37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d45d572c3c488599ef28a390ceb5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeedd734cffa43cdadf6ef1af69009de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 0:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 96.2%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e7a0a7f1a14ea28bdb63ca23f7cf69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4a80e6cbf846a496028be1e14c895d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 1:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 86.6%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b8b83089664aaaab24c01e14c0f381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 0:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on previous task 0: 89.75%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4f9ffb154f4487a5958b32972f7580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66180de305fc4a99818ec230e78e2670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 2:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 91.25%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da79631a07234ceca33734a304a61f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 0:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on previous task 0: 67.2%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f8426c9f7e4c428b1efa6e13ba2eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 1:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on previous task 1: 52.0%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee42da5aa7443a38063c87273786e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e23447035234c1c90871a5a855232cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 3:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 3: 97.45%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae17cbaa55c849c5a27c8e8556a90795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 0:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on previous task 0: 65.85%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea78a1b112b54d79a088f3d95a5a2a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 1:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on previous task 1: 71.55%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319bfa0efc7f4ed59c99e2a6736e9f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 2:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on previous task 2: 81.7%\n",
      "Training on task 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2242bf48e5bc45619d14920cfc6f0d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fa668b14d94e9b996053b95c3a9a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 4:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 4: 95.65%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a234662cd07f4392a4c9578f93d9be75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 0:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on previous task 0: 83.55%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e4e74adebf4bf28bb1fd9a715caa6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 1:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on previous task 1: 78.55%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10024b4158274cb19dcc04438d6dfc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 2:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on previous task 2: 75.45%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3207406858bf43159119da5cd04d7739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing Task 3:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on previous task 3: 86.9%\n",
      "Model saved to out/models/comp_disc_conv_s_cifar10_model_final.pth\n"
     ]
    }
   ],
   "source": [
    "model = CNN(in_channels=3, num_tasks=5, num_classes_per_task=2).to(device)\n",
    "train_cifar_split(\n",
    "    model, \n",
    "    \"mle_disc_conv_s_cifar10\", \n",
    "    cifar_train, \n",
    "    cifar_test, \n",
    "    train_task_ids, \n",
    "    test_task_ids, \n",
    "    device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e1923-d6b4-4043-98d2-abd6dc0bf5f1",
   "metadata": {},
   "source": [
    "## EWC Method for Split CIFAR10 with CNN/ResNet\n",
    "\n",
    "We may see significant improvements across tasks from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e11394a1-d3c7-4eb0-b5c4-fa1796027b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test models with EWC method on split cifar10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def compute_fisher_information(model, dataloader, task_idx, device):\n",
    "    model.eval()\n",
    "    fisher_information = {}\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            fisher_information[name] = torch.zeros_like(param.data)\n",
    "\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), binarize_y(target, task_idx).to(device)\n",
    "            with torch.enable_grad():  # Enables gradient calculation in this block\n",
    "                model.zero_grad()\n",
    "                output = model(data, task_idx)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                loss.backward()\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.grad is not None:\n",
    "                        fisher_information[name] += param.grad.data ** 2 / len(dataloader.dataset)\n",
    "    return fisher_information\n",
    "\n",
    "def modify_loss_function(original_loss, model, lambda_ewc, fisher_matrices, optimal_params):\n",
    "    ewc_loss = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in fisher_matrices:\n",
    "            fisher_matrix = fisher_matrices[name]\n",
    "            optimal_param = optimal_params[name].to(device)\n",
    "            ewc_loss += (fisher_matrix * (param - optimal_param) ** 2).sum()\n",
    "    return original_loss + lambda_ewc / 2 * ewc_loss\n",
    "\n",
    "def run_task_ewc(model, log_name, cifar_train, cifar_test, train_task_ids, test_task_ids, device, epochs, batch_size, lambda_ewc):\n",
    "    \"\"\"\n",
    "    Trains a given model on CIFAR10 split tasks using the Elastic Weight Consolidation (EWC) method.\n",
    "\n",
    "    Args:\n",
    "    - model: The model to train.\n",
    "    - log_name: Name for the TensorBoard logs.\n",
    "    - cifar_train: Training dataset.\n",
    "    - cifar_test: Test dataset.\n",
    "    - train_task_ids: Task IDs for the training data.\n",
    "    - test_task_ids: Task IDs for the test data.\n",
    "    - device: Torch device to use for training.\n",
    "    - epochs: Number of epochs to train each task.\n",
    "    - batch_size: Batch size for training and testing.\n",
    "    - lambda_ewc: The EWC penalty term lambda.\n",
    "    \"\"\"    \n",
    "    summary_writer = SummaryWriter(log_dir=os.path.join(\"logs\", log_name, datetime.now().strftime('%Y%m%d_%H%M%S')))\n",
    "    experiment_path = f\"out/experiments/{log_name}\"\n",
    "    os.makedirs(experiment_path, exist_ok=True)  # Ensure output directory exists\n",
    "    accuracies = {}\n",
    "    \n",
    "    previous_fisher_matrices = {}\n",
    "    previous_optimal_params = {}\n",
    "\n",
    "    for task_idx in range(5):\n",
    "        print(f\"Training on task {task_idx}\")\n",
    "        task_dataset = task_subset(cifar_train, train_task_ids, task_idx)\n",
    "        train_loader = DataLoader(task_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "        test_dataset = task_subset(cifar_test, test_task_ids, task_idx)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in tqdm(range(epochs), desc=f\"Training Task {task_idx}\"):\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), binarize_y(target, task_idx).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data, task_idx)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                if task_idx > 0:\n",
    "                    ewc_loss = modify_loss_function(loss, model, lambda_ewc, previous_fisher_matrices, previous_optimal_params)\n",
    "                    # print(f\"Task {task_idx}'s ewc_loss: \", ewc_loss)\n",
    "                    loss = ewc_loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            summary_writer.add_scalar(f'Task_{task_idx}/Train_Loss', loss.item(), epoch)\n",
    "\n",
    "        test_accuracy = test_model(model, test_loader, device, task_idx)\n",
    "        print(f\"Test accuracy on task {task_idx}: {test_accuracy}%\")\n",
    "        summary_writer.add_scalar(f'Task_{task_idx}/Test_Accuracy', test_accuracy, epoch)\n",
    "        accuracies[f\"TASK {task_idx}\"] = test_accuracy\n",
    "\n",
    "        for previous_task_idx in range(task_idx + 1):\n",
    "            test_dataset = task_subset(cifar_test, test_task_ids, previous_task_idx)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "            \n",
    "            accuracy = test_model(model, test_dataloader, device, previous_task_idx)\n",
    "            print(f\"Test accuracy on previous task {previous_task_idx}: {accuracy}%\")\n",
    "            summary_writer.add_scalar(f\"Cross_Task_Accuracy/task_{task_idx}_on_{previous_task_idx}\", accuracy, global_step=task_idx)\n",
    "            accuracies[f\"TASK {previous_task_idx}\"] = accuracy\n",
    "\n",
    "        # Update for EWC (after model.eval())\n",
    "        model.eval()\n",
    "        fisher_information = compute_fisher_information(model, train_loader, task_idx, device)\n",
    "        optimal_params = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if task_idx == 0:\n",
    "            previous_fisher_matrices = fisher_information\n",
    "            previous_optimal_params = optimal_params\n",
    "        else:\n",
    "            for name in fisher_information:\n",
    "                previous_fisher_matrices[name] += fisher_information[name]\n",
    "\n",
    "    # Save accuracies to file\n",
    "    import json\n",
    "    accuracies_file = os.path.join(experiment_path, \"final_accuracies.json\")\n",
    "    with open(accuracies_file, 'w') as f:\n",
    "        json.dump(accuracies, f)\n",
    "    print(f\"Accuracies saved to {accuracies_file}\")\n",
    "\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5a475cb2-58ed-43c5-8af4-3d2bb6f4b17c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93222487e22b456984b8001a0b5e6a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 0:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 96.25%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645eaff7aba34a42835a4f1c935e09b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 1:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 87.3%\n",
      "Test accuracy on previous task 0: 90.2%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79009b780a74bcabf2018f3d8407f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 2:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 91.6%\n",
      "Test accuracy on previous task 0: 88.65%\n",
      "Test accuracy on previous task 1: 70.05%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b29e59059e0467fbc22acc2161325ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 3:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on previous task 0: 89.3%\n",
      "Test accuracy on previous task 1: 70.8%\n",
      "Test accuracy on previous task 2: 86.1%\n",
      "Training on task 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d0b23c14b2467287b604427018b09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 4:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on previous task 0: 90.0%\n",
      "Test accuracy on previous task 1: 73.9%\n",
      "Test accuracy on previous task 2: 80.5%\n",
      "Test accuracy on previous task 3: 91.45%\n"
     ]
    }
   ],
   "source": [
    "lambda_ewc = 5000\n",
    "\n",
    "model = CNN(in_channels=3, num_tasks=5, num_classes_per_task=2).to(device)\n",
    "run_task_ewc(model, f\"ewc_conv_s_cifar10_lambda_ewc_{lambda_ewc}\", cifar_train, cifar_test, train_task_ids, test_task_ids, device, epochs=100, batch_size=256, lambda_ewc=lambda_ewc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89d9adea-1968-40d5-a036-a41353c1e545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a619babfda446d96f10877fc530730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 0:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 98.1%\n",
      "Test accuracy on previous task 0: 98.1%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940ec6b5eafc4b248c574f5bd62966f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 1:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 89.65%\n",
      "Test accuracy on previous task 0: 82.35%\n",
      "Test accuracy on previous task 1: 89.65%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab17f570be674ffebb3ff447f8607331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 2:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 94.25%\n",
      "Test accuracy on previous task 0: 75.5%\n",
      "Test accuracy on previous task 1: 80.85%\n",
      "Test accuracy on previous task 2: 94.25%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b65a6d1cd04b578da8e440053a307a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 3:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 3: 98.25%\n",
      "Test accuracy on previous task 0: 66.3%\n",
      "Test accuracy on previous task 1: 74.25%\n",
      "Test accuracy on previous task 2: 83.9%\n",
      "Test accuracy on previous task 3: 98.25%\n",
      "Training on task 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd06e90b9794ac0b30f24e5f29795d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 4:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 4: 97.0%\n",
      "Test accuracy on previous task 0: 75.9%\n",
      "Test accuracy on previous task 1: 68.05%\n",
      "Test accuracy on previous task 2: 73.65%\n",
      "Test accuracy on previous task 3: 88.4%\n",
      "Test accuracy on previous task 4: 97.0%\n",
      "Accuracies saved to out/experiments/ewc_resnet_s_cifar10_lambda_ewc_1/final_accuracies.json\n"
     ]
    }
   ],
   "source": [
    "lambda_ewc = 1\n",
    "model = ResNetCIFAR10(in_channels=3, num_tasks=5, num_classes_per_task=2).to(device)\n",
    "\n",
    "run_task_ewc(\n",
    "    model, \n",
    "    f\"ewc_resnet_s_cifar10_lambda_ewc_{lambda_ewc}\", \n",
    "    cifar_train, \n",
    "    cifar_test, \n",
    "    train_task_ids, \n",
    "    test_task_ids, \n",
    "    device,\n",
    "    epochs=100, \n",
    "    batch_size=256, \n",
    "    lambda_ewc=lambda_ewc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e17caa3f-21b6-48ef-80a6-6d0cb5b2e370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a9a5ed9fab4ee594004bd2f00d1e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 0:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on previous task 0: 96.2%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa29750281b49e5b2617756ce3993aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 1:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 87.3%\n",
      "Test accuracy on previous task 0: 92.6%\n",
      "Test accuracy on previous task 1: 87.3%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8d13a9a59c4bddb27084c3be2cba45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 2:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 92.25%\n",
      "Test accuracy on previous task 0: 83.35%\n",
      "Test accuracy on previous task 1: 69.25%\n",
      "Test accuracy on previous task 2: 92.25%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb363796b8a40fbbe30896574fb5d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 3:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 3: 97.5%\n",
      "Test accuracy on previous task 0: 84.25%\n",
      "Test accuracy on previous task 1: 71.15%\n",
      "Test accuracy on previous task 2: 88.15%\n",
      "Test accuracy on previous task 3: 97.5%\n",
      "Training on task 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4befc12c0f4140afa1fba44dd60079bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 4:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 4: 96.2%\n",
      "Test accuracy on previous task 0: 87.05%\n",
      "Test accuracy on previous task 1: 70.8%\n",
      "Test accuracy on previous task 2: 77.7%\n",
      "Test accuracy on previous task 3: 95.05%\n",
      "Test accuracy on previous task 4: 96.2%\n",
      "Accuracies saved to out/experiments/ewc_conv_CIFAR10_lambda_ewc_1/final_accuracies.json\n"
     ]
    }
   ],
   "source": [
    "lambda_ewc = 1\n",
    "\n",
    "model = CNN(in_channels=3, num_tasks=5, num_classes_per_task=2).to(device)\n",
    "run_task_ewc(model, f\"ewc_conv_CIFAR10_lambda_ewc_{lambda_ewc}\", cifar_train, cifar_test, train_task_ids, test_task_ids, device, epochs=100, batch_size=256, lambda_ewc=lambda_ewc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0813c-ffb3-49a0-b2c8-8c86ef1499e4",
   "metadata": {},
   "source": [
    "## Synaptic Intelligence (SI) for Split CIFAR10 with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ca37246-8539-4814-9ee2-dad57e77a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_si(model, log_name, cifar_train, cifar_test, train_task_ids, test_task_ids, device, epochs, batch_size, c_si):\n",
    "    \"\"\"\n",
    "    Trains a given model on CIFAR10 split tasks using the Synaptic Intelligence (SI) method.\n",
    "    \n",
    "    Args:\n",
    "    - model: The model to train.\n",
    "    - log_name: Name for the TensorBoard logs.\n",
    "    - cifar_train: Training dataset.\n",
    "    - cifar_test: Test dataset.\n",
    "    - train_task_ids: Task IDs for the training data.\n",
    "    - test_task_ids: Task IDs for the test data.\n",
    "    - device: Torch device to use for training.\n",
    "    - epochs: Number of epochs to train each task.\n",
    "    - batch_size: Batch size for training and testing.\n",
    "    - c_si: The SI regularization term coefficient.\n",
    "    \"\"\"\n",
    "    summary_writer = SummaryWriter(log_dir=os.path.join(\"logs\", log_name, datetime.now().strftime('%Y%m%d_%H%M%S')))\n",
    "    experiment_path = f\"out/experiments/{log_name}\"\n",
    "    os.makedirs(experiment_path, exist_ok=True)  # Ensure output directory exists\n",
    "    accuracies = {}\n",
    "    \n",
    "    # Initialize importance and previous parameters dictionaries\n",
    "    importance = {}\n",
    "    prev_params = {}\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            importance[name] = torch.zeros_like(param, device=device)\n",
    "            prev_params[name] = param.clone().detach()\n",
    "\n",
    "    for task_idx in range(5):\n",
    "        print(f\"Training on task {task_idx}\")\n",
    "        # Assume task_subset and binarize_y are defined elsewhere to handle task-specific data preparation\n",
    "        task_dataset = task_subset(cifar_train, train_task_ids, task_idx)\n",
    "        train_loader = DataLoader(task_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_dataset = task_subset(cifar_test, test_task_ids, task_idx)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in tqdm(range(epochs), desc=f\"Training Task {task_idx}\"):\n",
    "            model.train()\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), binarize_y(target, task_idx).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data, task_idx)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                \n",
    "                # Backpropagate to compute gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # Calculate SI regularization term and add it to the loss before optimizer step\n",
    "                si_reg_loss = sum((importance[name] * (param - prev_params[name]) ** 2).sum() for name, param in model.named_parameters() if param.requires_grad)\n",
    "                (c_si * si_reg_loss).backward() \n",
    "                \n",
    "                optimizer.step()\n",
    "\n",
    "                # Update the importance weights after optimizer step\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.requires_grad:\n",
    "                        delta_param = param.detach() - prev_params[name]\n",
    "                        # Assuming a zero-initialized importance, this needs accumulation of gradient information over tasks\n",
    "                        importance[name] += (param.grad.detach() ** 2) * delta_param.abs()\n",
    "            summary_writer.add_scalar(f'Task_{task_idx}/Train_Loss', loss.item(), epoch)\n",
    "        \n",
    "        # Evaluate the model on the current task's test set\n",
    "        test_accuracy = test_model(model, test_loader, device, task_idx)\n",
    "        print(f\"Test accuracy on task {task_idx}: {test_accuracy}%\")\n",
    "        summary_writer.add_scalar(f'Task_{task_idx}/Test_Accuracy', test_accuracy, epoch)\n",
    "        accuracies[f\"TASK {task_idx}\"] = test_accuracy\n",
    "        \n",
    "        # Evaluate the model on all previous tasks' test sets to measure forgetting\n",
    "        for previous_task_idx in range(task_idx + 1):\n",
    "            test_dataset = task_subset(cifar_test, test_task_ids, previous_task_idx)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "            accuracy = test_model(model, test_dataloader, device, previous_task_idx)\n",
    "            print(f\"Test accuracy on previous task {previous_task_idx}: {accuracy}%\")\n",
    "            summary_writer.add_scalar(f\"Cross_Task_Accuracy/task_{task_idx}_on_{previous_task_idx}\", accuracy, global_step=task_idx)\n",
    "            accuracies[f\"TASK {previous_task_idx}\"] = accuracy\n",
    "        \n",
    "        # After task training, update previous parameters for the next task\n",
    "        prev_params = {name: param.clone().detach() for name, param in model.named_parameters() if param.requires_grad}\n",
    "\n",
    "\n",
    "    # Save accuracies to file\n",
    "    accuracies_file = os.path.join(experiment_path, \"final_accuracies.json\")\n",
    "    with open(accuracies_file, 'w') as f:\n",
    "        json.dump(accuracies, f)\n",
    "    print(f\"Accuracies saved to {accuracies_file}\")\n",
    "\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2aba5757-3b8e-480e-9889-17334ba753b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd1a5ffdfc84ba79120b03c93977fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 0:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 87.05%\n",
      "Test accuracy on task 0: 92.8%\n",
      "Test accuracy on task 0: 94.3%\n",
      "Test accuracy on task 0: 94.0%\n",
      "Test accuracy on task 0: 93.9%\n",
      "Test accuracy on task 0: 95.55%\n",
      "Test accuracy on task 0: 95.15%\n",
      "Test accuracy on task 0: 93.5%\n",
      "Test accuracy on task 0: 95.75%\n",
      "Test accuracy on task 0: 96.0%\n",
      "Test accuracy on task 0: 95.85%\n",
      "Test accuracy on task 0: 95.7%\n",
      "Test accuracy on task 0: 95.7%\n",
      "Test accuracy on task 0: 95.6%\n",
      "Test accuracy on task 0: 96.3%\n",
      "Test accuracy on task 0: 95.45%\n",
      "Test accuracy on task 0: 96.3%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.1%\n",
      "Test accuracy on task 0: 96.1%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.05%\n",
      "Test accuracy on task 0: 96.1%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.1%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.1%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.15%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.2%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.3%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.35%\n",
      "Test accuracy on task 0: 96.25%\n",
      "Test accuracy on task 0: 96.3%\n",
      "Test accuracy on task 0: 96.3%\n",
      "Test accuracy on task 0: 96.3%\n",
      "Test accuracy on task 0: 96.3%\n",
      "Test accuracy on task 0: 96.3%\n",
      "Test accuracy on task 0: 96.35%\n",
      "Test accuracy on task 0: 96.3%\n",
      "Test accuracy on task 0: 96.35%\n",
      "Test accuracy on task 0: 96.3%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a1a456fa474915a2ecabd4dd87f052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 1:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 77.55%\n",
      "Test accuracy on task 1: 81.6%\n",
      "Test accuracy on task 1: 80.85%\n",
      "Test accuracy on task 1: 83.65%\n",
      "Test accuracy on task 1: 85.1%\n",
      "Test accuracy on task 1: 84.6%\n",
      "Test accuracy on task 1: 84.45%\n",
      "Test accuracy on task 1: 78.6%\n",
      "Test accuracy on task 1: 84.8%\n",
      "Test accuracy on task 1: 85.75%\n",
      "Test accuracy on task 1: 85.2%\n",
      "Test accuracy on task 1: 85.9%\n",
      "Test accuracy on task 1: 85.3%\n",
      "Test accuracy on task 1: 86.2%\n",
      "Test accuracy on task 1: 85.85%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.3%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.3%\n",
      "Test accuracy on task 1: 86.25%\n",
      "Test accuracy on task 1: 86.1%\n",
      "Test accuracy on task 1: 86.15%\n",
      "Test accuracy on task 1: 86.3%\n",
      "Test accuracy on task 1: 86.15%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.25%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.25%\n",
      "Test accuracy on task 1: 86.25%\n",
      "Test accuracy on task 1: 86.3%\n",
      "Test accuracy on task 1: 86.2%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.25%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.3%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.3%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.45%\n",
      "Test accuracy on task 1: 86.45%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.3%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.3%\n",
      "Test accuracy on task 1: 86.3%\n",
      "Test accuracy on task 1: 86.3%\n",
      "Test accuracy on task 1: 86.25%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.25%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.25%\n",
      "Test accuracy on task 1: 86.45%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.45%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on task 1: 86.3%\n",
      "Test accuracy on task 1: 86.45%\n",
      "Test accuracy on task 1: 86.45%\n",
      "Test accuracy on task 1: 86.45%\n",
      "Test accuracy on task 1: 86.6%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.35%\n",
      "Test accuracy on task 1: 86.45%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on task 1: 86.3%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.45%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on task 1: 86.4%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on task 1: 86.5%\n",
      "Test accuracy on previous task 0: 89.05%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a105b3c93d1486499af7797305267d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 2:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 85.65%\n",
      "Test accuracy on task 2: 88.8%\n",
      "Test accuracy on task 2: 89.45%\n",
      "Test accuracy on task 2: 84.25%\n",
      "Test accuracy on task 2: 90.3%\n",
      "Test accuracy on task 2: 90.05%\n",
      "Test accuracy on task 2: 89.75%\n",
      "Test accuracy on task 2: 89.65%\n",
      "Test accuracy on task 2: 90.65%\n",
      "Test accuracy on task 2: 89.75%\n",
      "Test accuracy on task 2: 90.8%\n",
      "Test accuracy on task 2: 91.1%\n",
      "Test accuracy on task 2: 91.25%\n",
      "Test accuracy on task 2: 90.85%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.15%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.15%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.15%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.1%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 90.95%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 90.95%\n",
      "Test accuracy on task 2: 91.15%\n",
      "Test accuracy on task 2: 90.9%\n",
      "Test accuracy on task 2: 90.95%\n",
      "Test accuracy on task 2: 90.95%\n",
      "Test accuracy on task 2: 91.1%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 90.95%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 90.95%\n",
      "Test accuracy on task 2: 90.95%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 90.9%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 90.95%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.0%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.1%\n",
      "Test accuracy on task 2: 91.1%\n",
      "Test accuracy on task 2: 91.1%\n",
      "Test accuracy on task 2: 91.05%\n",
      "Test accuracy on task 2: 91.15%\n",
      "Test accuracy on task 2: 91.1%\n",
      "Test accuracy on previous task 0: 86.05%\n",
      "Test accuracy on previous task 1: 68.55%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7825200a7d945358fc74d34b436285a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 3:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 3: 95.4%\n",
      "Test accuracy on task 3: 95.2%\n",
      "Test accuracy on task 3: 96.6%\n",
      "Test accuracy on task 3: 95.55%\n",
      "Test accuracy on task 3: 96.4%\n",
      "Test accuracy on task 3: 96.85%\n",
      "Test accuracy on task 3: 96.8%\n",
      "Test accuracy on task 3: 96.9%\n",
      "Test accuracy on task 3: 95.4%\n",
      "Test accuracy on task 3: 96.95%\n",
      "Test accuracy on task 3: 96.4%\n",
      "Test accuracy on task 3: 95.9%\n",
      "Test accuracy on task 3: 96.85%\n",
      "Test accuracy on task 3: 97.05%\n",
      "Test accuracy on task 3: 96.95%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.2%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.15%\n",
      "Test accuracy on task 3: 97.15%\n",
      "Test accuracy on task 3: 97.15%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.15%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.15%\n",
      "Test accuracy on task 3: 97.15%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.2%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.2%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.15%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.15%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.2%\n",
      "Test accuracy on task 3: 97.2%\n",
      "Test accuracy on task 3: 97.2%\n",
      "Test accuracy on task 3: 97.1%\n",
      "Test accuracy on task 3: 97.05%\n",
      "Test accuracy on task 3: 97.1%\n",
      "Test accuracy on task 3: 97.15%\n",
      "Test accuracy on task 3: 97.15%\n",
      "Test accuracy on task 3: 97.2%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.2%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on task 3: 97.3%\n",
      "Test accuracy on task 3: 97.25%\n",
      "Test accuracy on previous task 0: 83.8%\n",
      "Test accuracy on previous task 1: 76.6%\n",
      "Test accuracy on previous task 2: 83.65%\n",
      "Training on task 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c0be9a52174a7db7732b33ee08579f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 4:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 4: 90.65%\n",
      "Test accuracy on task 4: 93.35%\n",
      "Test accuracy on task 4: 94.8%\n",
      "Test accuracy on task 4: 95.05%\n",
      "Test accuracy on task 4: 93.5%\n",
      "Test accuracy on task 4: 95.3%\n",
      "Test accuracy on task 4: 95.35%\n",
      "Test accuracy on task 4: 95.4%\n",
      "Test accuracy on task 4: 95.7%\n",
      "Test accuracy on task 4: 95.75%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 96.05%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 96.05%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 96.1%\n",
      "Test accuracy on task 4: 96.1%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 96.1%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.8%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.8%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.8%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.8%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.75%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 96.0%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.8%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.95%\n",
      "Test accuracy on task 4: 95.85%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on task 4: 95.9%\n",
      "Test accuracy on previous task 0: 80.8%\n",
      "Test accuracy on previous task 1: 71.35%\n",
      "Test accuracy on previous task 2: 73.25%\n",
      "Test accuracy on previous task 3: 95.25%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "c_si = 1\n",
    "log_name = f\"si_conv_s_CIFAR10_c_si_{c_si}\" \n",
    "model = CNN(in_channels=3, num_tasks=5, num_classes_per_task=2).to(device)\n",
    "\n",
    "run_task_si(\n",
    "    model=model,\n",
    "    log_name=log_name,\n",
    "    cifar_train=cifar_train,\n",
    "    cifar_test=cifar_test,\n",
    "    train_task_ids=train_task_ids,\n",
    "    test_task_ids=test_task_ids,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    c_si=c_si\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c698e7bc-02f7-4368-98bd-f2ae282a0caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90965155bc24a3ba9f1e8b422b32692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 0:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 97.45%\n",
      "Test accuracy on previous task 0: 97.45%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384b775ae7594d018fd4dd85088a9004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 1:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 90.15%\n",
      "Test accuracy on previous task 0: 85.0%\n",
      "Test accuracy on previous task 1: 90.15%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dc9582b79c4feaa04395e00026d81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 2:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 94.15%\n",
      "Test accuracy on previous task 0: 70.9%\n",
      "Test accuracy on previous task 1: 77.5%\n",
      "Test accuracy on previous task 2: 94.15%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59df56f22aa14438bbdc4ac5dcf6c318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 3:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 3: 97.7%\n",
      "Test accuracy on previous task 0: 59.85%\n",
      "Test accuracy on previous task 1: 70.4%\n",
      "Test accuracy on previous task 2: 86.85%\n",
      "Test accuracy on previous task 3: 97.7%\n",
      "Training on task 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29b83cb2667448e9738fd770a4e7433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 4:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 4: 97.15%\n",
      "Test accuracy on previous task 0: 68.75%\n",
      "Test accuracy on previous task 1: 69.7%\n",
      "Test accuracy on previous task 2: 83.35%\n",
      "Test accuracy on previous task 3: 92.65%\n",
      "Test accuracy on previous task 4: 97.15%\n",
      "Accuracies saved to out/experiments/si_resnet_s_CIFAR10_c_si_1/final_accuracies.json\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 256\n",
    "c_si = 1\n",
    "log_name = f\"si_resnet_s_CIFAR10_c_si_{c_si}\" \n",
    "model = ResNetCIFAR10(in_channels=3, num_tasks=5, num_classes_per_task=2).to(device)\n",
    "\n",
    "run_task_si(\n",
    "    model=model,\n",
    "    log_name=log_name,\n",
    "    cifar_train=cifar_train,\n",
    "    cifar_test=cifar_test,\n",
    "    train_task_ids=train_task_ids,\n",
    "    test_task_ids=test_task_ids,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    c_si=c_si\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb0954-85f5-4c66-8b7a-bd94fd9f90d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Laplace Propagation Method for Split CIFAR10 Task with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "501ca0a8-227e-4b11-9403-495e63232939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hessian_diag(model, dataloader, device, task_idx):\n",
    "    model.eval()\n",
    "    hessian_diag = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        hessian_diag[name] = torch.zeros_like(param)\n",
    "\n",
    "    for data, target in dataloader:\n",
    "        data, target = data.to(device), binarize_y(target, task_idx).to(device)\n",
    "        model.zero_grad()\n",
    "        output = model(data, task_idx)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        # Set allow_unused=True to handle parameters not used in the graph\n",
    "        grad_params = torch.autograd.grad(loss, model.parameters(), create_graph=True, allow_unused=True)\n",
    "\n",
    "        for grad, (name, param) in zip(grad_params, model.named_parameters()):\n",
    "            if grad is not None:  # Only proceed if the gradient is not None\n",
    "                grad2 = torch.autograd.grad(grad.sum(), param, retain_graph=True, allow_unused=True)[0]\n",
    "                if grad2 is not None:  # Check if the second derivative is not None\n",
    "                    hessian_diag[name] += grad2.data / len(dataloader.dataset)\n",
    "\n",
    "    return hessian_diag\n",
    "\n",
    "\n",
    "def run_task_lp(model, log_name, cifar_train, cifar_test, train_task_ids, test_task_ids, device, epochs, batch_size, gamma_lp):\n",
    "    \"\"\"\n",
    "    Trains a given model on CIFAR10 split tasks using a simplified Laplace Propagation method (approximated with second-order Taylor Expansion).\n",
    "    \n",
    "    Args:\n",
    "    - model: The model to train.\n",
    "    - log_name: Name for the TensorBoard logs.\n",
    "    - cifar_train: Training dataset.\n",
    "    - cifar_test: Test dataset.\n",
    "    - train_task_ids: Task IDs for the training data.\n",
    "    - test_task_ids: Task IDs for the test data.\n",
    "    - device: Torch device to use for training.\n",
    "    - epochs: Number of epochs to train each task.\n",
    "    - batch_size: Batch size for training and testing.\n",
    "    - gamma_lp: Coefficient for the LP regularization term.\n",
    "    \"\"\"\n",
    "    summary_writer = SummaryWriter(log_dir=os.path.join(\"logs\", log_name, datetime.now().strftime('%Y%m%d_%H%M%S')))\n",
    "    experiment_path = f\"out/experiments/{log_name}\"\n",
    "    os.makedirs(experiment_path, exist_ok=True)  # Ensure output directory exists\n",
    "    accuracies = {}\n",
    "    \n",
    "    # Initialize Hessian approximation (diagonal) and previous parameters\n",
    "    hessian_diag = {}\n",
    "    prev_params = {}\n",
    "\n",
    "    for task_idx in range(5):\n",
    "        print(f\"Training on task {task_idx}\")\n",
    "        task_dataset = task_subset(cifar_train, train_task_ids, task_idx)\n",
    "        train_loader = DataLoader(task_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_dataset = task_subset(cifar_test, test_task_ids, task_idx)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in tqdm(range(epochs), desc=f\"Training Task {task_idx}\"):\n",
    "            model.train()\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), binarize_y(target, task_idx).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data, task_idx)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                \n",
    "                if task_idx > 0:\n",
    "                    # Calculate LP regularization term\n",
    "                    lp_loss = 0\n",
    "                    for name, param in model.named_parameters():\n",
    "                        if name in hessian_diag:\n",
    "                            lp_loss += (hessian_diag[name] * (param - prev_params[name]) ** 2).sum()\n",
    "                    loss += gamma_lp * lp_loss\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Update Hessian approximation and previous parameters after each epoch\n",
    "            if task_idx > 0:\n",
    "                hessian_diag = compute_hessian_diag(model, train_loader, device, task_idx)\n",
    "            prev_params = {name: param.clone().detach() for name, param in model.named_parameters()}\n",
    "\n",
    "            summary_writer.add_scalar(f'Task_{task_idx}/Train_Loss', loss.item(), epoch)\n",
    "            \n",
    "        # Evaluate the model on the current task's test set\n",
    "        test_accuracy = test_model(model, test_loader, device, task_idx)\n",
    "        print(f\"Test accuracy on task {task_idx}: {test_accuracy}%\")\n",
    "        summary_writer.add_scalar(f'Task_{task_idx}/Test_Accuracy', test_accuracy, epoch)\n",
    "        accuracies[f\"TASK {task_idx}\"] = test_accuracy\n",
    "\n",
    "        # Evaluate the model on all previous tasks' test sets to measure forgetting\n",
    "        for previous_task_idx in range(task_idx + 1):\n",
    "            test_dataset = task_subset(cifar_test, test_task_ids, previous_task_idx)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "            accuracy = test_model(model, test_dataloader, device, previous_task_idx)\n",
    "            print(f\"Test accuracy on previous task {previous_task_idx}: {accuracy}%\")\n",
    "            summary_writer.add_scalar(f\"Cross_Task_Accuracy/task_{task_idx}_on_{previous_task_idx}\", accuracy, global_step=task_idx)\n",
    "            accuracies[f\"TASK {previous_task_idx}\"] = accuracy\n",
    "\n",
    "    # Save accuracies to file\n",
    "    accuracies_file = os.path.join(experiment_path, \"final_accuracies.json\")\n",
    "    with open(accuracies_file, 'w') as f:\n",
    "        json.dump(accuracies, f)\n",
    "    print(f\"Accuracies saved to {accuracies_file}\")\n",
    "    \n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5d2f3b2-b180-4284-9a1c-bca7a5531644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e25b4dd979f4edda5c8b97f30e82c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 0:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 95.9%\n",
      "Test accuracy on previous task 0: 95.9%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0ac8018f704b9da4ed16266b1926b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 1:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 64.4%\n",
      "Test accuracy on previous task 0: 86.0%\n",
      "Test accuracy on previous task 1: 64.4%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b009279d02874532b3e59773d2e8c7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 2:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 59.2%\n",
      "Test accuracy on previous task 0: 80.0%\n",
      "Test accuracy on previous task 1: 56.0%\n",
      "Test accuracy on previous task 2: 59.2%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7037ba5791864fadbc92abc4f7718471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 3:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m log_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlp_conv_CIFAR10_gamma_lp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgamma_lp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, num_tasks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, num_classes_per_task\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m run_task_lp(\n\u001b[1;32m     10\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     11\u001b[0m     log_name\u001b[38;5;241m=\u001b[39mlog_name,\n\u001b[1;32m     12\u001b[0m     cifar_train\u001b[38;5;241m=\u001b[39mcifar_train,\n\u001b[1;32m     13\u001b[0m     cifar_test\u001b[38;5;241m=\u001b[39mcifar_test,\n\u001b[1;32m     14\u001b[0m     train_task_ids\u001b[38;5;241m=\u001b[39mtrain_task_ids,\n\u001b[1;32m     15\u001b[0m     test_task_ids\u001b[38;5;241m=\u001b[39mtest_task_ids,\n\u001b[1;32m     16\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     17\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[1;32m     18\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     19\u001b[0m     gamma_lp\u001b[38;5;241m=\u001b[39mgamma_lp\n\u001b[1;32m     20\u001b[0m )\n",
      "Cell \u001b[0;32mIn[7], line 61\u001b[0m, in \u001b[0;36mrun_task_lp\u001b[0;34m(model, log_name, cifar_train, cifar_test, train_task_ids, test_task_ids, device, epochs, batch_size, gamma_lp)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     60\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     62\u001b[0m         data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), binarize_y(target, task_idx)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     63\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/scratch-ssd/ms23jh/conda_envs/llm/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/scratch-ssd/ms23jh/conda_envs/llm/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/scratch-ssd/ms23jh/conda_envs/llm/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/scratch-ssd/ms23jh/conda_envs/llm/lib/python3.11/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m/scratch-ssd/ms23jh/conda_envs/llm/lib/python3.11/site-packages/torch/utils/data/dataset.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m/scratch-ssd/ms23jh/conda_envs/llm/lib/python3.11/site-packages/torchvision/datasets/cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    115\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m/scratch-ssd/ms23jh/conda_envs/llm/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/scratch-ssd/ms23jh/conda_envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/scratch-ssd/ms23jh/conda_envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch-ssd/ms23jh/conda_envs/llm/lib/python3.11/site-packages/torchvision/transforms/transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mnormalize(tensor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[0;32m/scratch-ssd/ms23jh/conda_envs/llm/lib/python3.11/site-packages/torchvision/transforms/functional.py:349\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mnormalize(tensor, mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd, inplace\u001b[38;5;241m=\u001b[39minplace)\n",
      "File \u001b[0;32m/scratch-ssd/ms23jh/conda_envs/llm/lib/python3.11/site-packages/torchvision/transforms/_functional_tensor.py:919\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    917\u001b[0m dtype \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    918\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 919\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (std \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 100 \n",
    "batch_size = 256 \n",
    "gamma_lp = 0.05\n",
    "log_name = f\"lp_conv_CIFAR10_gamma_lp_{gamma_lp}\" \n",
    "\n",
    "model = CNN(in_channels=3, num_tasks=5, num_classes_per_task=2).to(device)\n",
    "\n",
    "run_task_lp(\n",
    "    model=model,\n",
    "    log_name=log_name,\n",
    "    cifar_train=cifar_train,\n",
    "    cifar_test=cifar_test,\n",
    "    train_task_ids=train_task_ids,\n",
    "    test_task_ids=test_task_ids,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    gamma_lp=gamma_lp\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5919fe6-9732-44a0-ac81-4f7c3f579afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 100 \n",
    "batch_size = 256 \n",
    "gamma_lp = 0.05\n",
    "log_name = f\"lp_resnet_CIFAR10_gamma_lp_{gamma_lp}\" \n",
    "\n",
    "model = ResNetCIFAR10(in_channels=3, num_tasks=5, num_classes_per_task=2).to(device)\n",
    "\n",
    "run_task_lp(\n",
    "    model=model,\n",
    "    log_name=log_name,\n",
    "    cifar_train=cifar_train,\n",
    "    cifar_test=cifar_test,\n",
    "    train_task_ids=train_task_ids,\n",
    "    test_task_ids=test_task_ids,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    gamma_lp=gamma_lp\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
