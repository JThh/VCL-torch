{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84cb1cd5-cf90-403c-ad65-3f638f3ef83c",
   "metadata": {},
   "source": [
    "# Experiment with MLP via Various Non-VCL Approaches (e.g. MAP, LP, EWC, SI) on Split-MNIST Task\n",
    "\n",
    "The models are configured in almost the same way (in terms of widths and depths) as in the VCL experiments, namely MLPs.\n",
    "\n",
    "This notebook is mainly meant for **replicaing the experiments from the VARIATIONAL CONTINUAL LEARNING paper.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d0b355-b9e1-49e8-8bc5-8e5cdc2be70c",
   "metadata": {},
   "source": [
    "## Model Definition and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f67058a-272b-4204-9fc4-81c28984e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d61dc52-73d3-40e1-8302-c95be5e115ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define non-vcl MLP with task heads \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=1*28*28, num_tasks=5, num_classes_per_task=2):\n",
    "        super(MLP, self).__init__()\n",
    "        # Shared layers\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        # Task-specific heads\n",
    "        self.task_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(128, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, num_classes_per_task)\n",
    "            ) for _ in range(num_tasks)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, task_idx):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        shared_output = self.shared_layers(x)\n",
    "        task_output = self.task_heads[task_idx](shared_output)\n",
    "        return F.log_softmax(task_output, dim=1)\n",
    "\n",
    "\n",
    "# For justifying that CNN-3 can also perform well on Split MNIST, without VCL. \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_tasks=5, num_classes_per_task=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.shared_conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.fc_input_dim = 256 * 3 * 3\n",
    "        \n",
    "        self.task_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.fc_input_dim, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, num_classes_per_task)\n",
    "            ) for _ in range(num_tasks)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, task_idx):\n",
    "        x = self.shared_conv_layers(x)\n",
    "        x = x.view(-1, self.fc_input_dim)  # Flatten\n",
    "        task_output = self.task_heads[task_idx](x)\n",
    "        return F.log_softmax(task_output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f039d78-1220-4b1f-9ca3-7fc4f3d49693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get split MNIST dataset\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "from util.transforms import Flatten, Scale\n",
    "\n",
    "# transform = Compose([ToTensor(), Flatten(), Scale()])\n",
    "transform = Compose([ToTensor(), Scale()])\n",
    "\n",
    "# download dataset\n",
    "mnist_train = MNIST(root=\"data\", train=True, download=False, transform=transform)\n",
    "mnist_test = MNIST(root=\"data\", train=False, download=False, transform=transform)\n",
    "\n",
    "label_to_task_mapping = {\n",
    "    0: 0, 1: 0,\n",
    "    2: 1, 3: 1,\n",
    "    4: 2, 5: 2,\n",
    "    6: 3, 7: 3,\n",
    "    8: 4, 9: 4,\n",
    "}\n",
    "\n",
    "train_task_ids = torch.Tensor([label_to_task_mapping[y] for _, y in mnist_train])\n",
    "test_task_ids = torch.Tensor([label_to_task_mapping[y] for _, y in mnist_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deddf21-5060-49f4-8e15-25e7045809a4",
   "metadata": {},
   "source": [
    "## MLE / MAP for Split MNIST with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "509622fa-e9e9-4a7b-8940-c378b9c05cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on Split MNIST without any CL strategies.\n",
    "import os\n",
    "import json\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from util.operations import task_subset\n",
    "\n",
    "binarize_y = lambda y, task: (y == (2 * task + 1)).long()\n",
    "\n",
    "\n",
    "def test_model(model, dataloader, device, task_idx):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data[0].to(device), binarize_y(data[1], task_idx).to(device)\n",
    "            outputs = model(images, task_idx)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_mnist_split(model, log_name, mnist_train, mnist_test, train_task_ids, test_task_ids, device):\n",
    "    \"\"\"\n",
    "    Trains a given model on a split MNIST dataset without continual learning strategies.\n",
    "\n",
    "    \"\"\"\n",
    "    # Setup TensorBoard writer\n",
    "    summary_logdir = os.path.join(\"logs\", log_name, datetime.now().strftime('%b%d_%H-%M-%S'))\n",
    "    summary_writer = SummaryWriter(summary_logdir)\n",
    "    os.makedirs(\"out/models/\", exist_ok=True)  # Ensure output directory exists\n",
    "    experiment_path = f\"out/experiments/{log_name}\"\n",
    "    os.makedirs(experiment_path, exist_ok=True)  # Ensure output directory exists\n",
    "    accuracies = {}\n",
    "\n",
    "    num_tasks = 5\n",
    "    for task_idx in range(num_tasks):\n",
    "        print(f\"Training on task {task_idx}\")\n",
    "        task_dataset = task_subset(mnist_train, train_task_ids, task_idx)\n",
    "        task_dataloader = DataLoader(task_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "        test_dataset = task_subset(mnist_test, test_task_ids, task_idx)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in tqdm(range(100), desc=f\"Epoch: \"):\n",
    "            for images, labels in task_dataloader:\n",
    "                images, labels = images.to(device), binarize_y(labels, task_idx).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images, task_idx)\n",
    "                loss = F.nll_loss(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            summary_writer.add_scalar(f'Task_{task_idx}/Train_Loss', loss.item(), epoch)\n",
    "\n",
    "        task_accuracy = test_model(model, test_dataloader, device, task_idx)\n",
    "        print(f\"Test accuracy on task {task_idx}: {task_accuracy}%\")\n",
    "        summary_writer.add_scalar(f\"Accuracy/task_{task_idx}\", task_accuracy, global_step=task_idx)\n",
    "        accuracies[f\"TASK {task_idx}\"] = task_accuracy\n",
    "\n",
    "        for previous_task_idx in range(task_idx + 1):\n",
    "            test_dataset = task_subset(mnist_test, test_task_ids, previous_task_idx)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "            \n",
    "            accuracy = test_model(model, test_dataloader, device, previous_task_idx)\n",
    "            print(f\"Test accuracy on previous task {previous_task_idx}: {accuracy}%\")\n",
    "            summary_writer.add_scalar(f\"Cross_Task_Accuracy/task_{task_idx}_on_{previous_task_idx}\", accuracy, global_step=task_idx)\n",
    "            accuracies[f\"TASK {previous_task_idx}\"] = task_accuracy\n",
    "            \n",
    "    # Save model state\n",
    "    model_save_path = os.path.join(\"out/models/\", f\"{log_name}_model_final.pth\")\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "    # Save accuracies to file\n",
    "    accuracies_file = os.path.join(experiment_path, \"final_accuracies.json\")\n",
    "    with open(accuracies_file, 'w') as f:\n",
    "        json.dump(accuracies, f)\n",
    "    print(f\"Accuracies saved to {accuracies_file}\")\n",
    "\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e1923-d6b4-4043-98d2-abd6dc0bf5f1",
   "metadata": {},
   "source": [
    "## EWC Method for Split MNIST with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e11394a1-d3c7-4eb0-b5c4-fa1796027b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test models with EWC method on split cifar10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def compute_fisher_information(model, dataloader, task_idx, device):\n",
    "    model.eval()\n",
    "    fisher_information = {}\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            fisher_information[name] = torch.zeros_like(param.data)\n",
    "\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), binarize_y(target, task_idx).to(device)\n",
    "            with torch.enable_grad():  # Enables gradient calculation in this block\n",
    "                model.zero_grad()\n",
    "                output = model(data, task_idx)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                loss.backward()\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.grad is not None:\n",
    "                        fisher_information[name] += param.grad.data ** 2 / len(dataloader.dataset)\n",
    "    return fisher_information\n",
    "\n",
    "def modify_loss_function(original_loss, model, lambda_ewc, fisher_matrices, optimal_params):\n",
    "    ewc_loss = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in fisher_matrices:\n",
    "            fisher_matrix = fisher_matrices[name]\n",
    "            optimal_param = optimal_params[name].to(device)\n",
    "            ewc_loss += (fisher_matrix * (param - optimal_param) ** 2).sum()\n",
    "    return original_loss + lambda_ewc / 2 * ewc_loss\n",
    "\n",
    "def run_task_ewc(model, log_name, mnist_train, mnist_test, train_task_ids, test_task_ids, device, epochs, batch_size, lambda_ewc):\n",
    "    \"\"\"\n",
    "    Trains a given model on MNIST split tasks using the Elastic Weight Consolidation (EWC) method.\n",
    "\n",
    "    \"\"\"    \n",
    "    summary_writer = SummaryWriter(log_dir=os.path.join(\"logs\", log_name, datetime.now().strftime('%Y%m%d_%H%M%S')))\n",
    "    experiment_path = f\"out/experiments/{log_name}\"\n",
    "    os.makedirs(experiment_path, exist_ok=True)  # Ensure output directory exists\n",
    "    accuracies = {}\n",
    "    \n",
    "    previous_fisher_matrices = {}\n",
    "    previous_optimal_params = {}\n",
    "\n",
    "    for task_idx in range(5):\n",
    "        print(f\"Training on task {task_idx}\")\n",
    "        task_dataset = task_subset(mnist_train, train_task_ids, task_idx)\n",
    "        train_loader = DataLoader(task_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "        test_dataset = task_subset(mnist_test, test_task_ids, task_idx)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in tqdm(range(epochs), desc=f\"Training Task {task_idx}\"):\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), binarize_y(target, task_idx).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data, task_idx)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                if task_idx > 0:\n",
    "                    ewc_loss = modify_loss_function(loss, model, lambda_ewc, previous_fisher_matrices, previous_optimal_params)\n",
    "                    # print(f\"Task {task_idx}'s ewc_loss: \", ewc_loss)\n",
    "                    loss = ewc_loss\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            summary_writer.add_scalar(f'Task_{task_idx}/Train_Loss', loss.item(), epoch)\n",
    "\n",
    "        test_accuracy = test_model(model, test_loader, device, task_idx)\n",
    "        print(f\"Test accuracy on task {task_idx}: {test_accuracy}%\")\n",
    "        summary_writer.add_scalar(f'Task_{task_idx}/Test_Accuracy', test_accuracy, epoch)\n",
    "        accuracies[f\"TASK {task_idx}\"] = test_accuracy\n",
    "\n",
    "        for previous_task_idx in range(task_idx + 1):\n",
    "            test_dataset = task_subset(mnist_test, test_task_ids, previous_task_idx)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "            \n",
    "            accuracy = test_model(model, test_dataloader, device, previous_task_idx)\n",
    "            print(f\"Test accuracy on previous task {previous_task_idx}: {accuracy}%\")\n",
    "            summary_writer.add_scalar(f\"Cross_Task_Accuracy/task_{task_idx}_on_{previous_task_idx}\", accuracy, global_step=task_idx)\n",
    "            accuracies[f\"TASK {previous_task_idx}\"] = accuracy\n",
    "\n",
    "        # Update for EWC (after model.eval())\n",
    "        model.eval()\n",
    "        fisher_information = compute_fisher_information(model, train_loader, task_idx, device)\n",
    "        optimal_params = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        if task_idx == 0:\n",
    "            previous_fisher_matrices = fisher_information\n",
    "            previous_optimal_params = optimal_params\n",
    "        else:\n",
    "            for name in fisher_information:\n",
    "                previous_fisher_matrices[name] += fisher_information[name]\n",
    "\n",
    "    # Save accuracies to file\n",
    "    import json\n",
    "    accuracies_file = os.path.join(experiment_path, \"final_accuracies.json\")\n",
    "    with open(accuracies_file, 'w') as f:\n",
    "        json.dump(accuracies, f)\n",
    "    print(f\"Accuracies saved to {accuracies_file}\")\n",
    "\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a475cb2-58ed-43c5-8af4-3d2bb6f4b17c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afe75306f0b469b8064f9648bc1b16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 0:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 99.95271867612293%\n",
      "Test accuracy on previous task 0: 99.95271867612293%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0bbde5271546dabcc4433b8f43318e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 1:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 99.36336924583742%\n",
      "Test accuracy on previous task 0: 99.90543735224587%\n",
      "Test accuracy on previous task 1: 99.36336924583742%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd46b21728eb496da963178c31d82238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 2:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 99.94663820704376%\n",
      "Test accuracy on previous task 0: 98.39243498817967%\n",
      "Test accuracy on previous task 1: 83.34965719882469%\n",
      "Test accuracy on previous task 2: 99.94663820704376%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015981b0eb344e1cacaefb00ae08e4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 3:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 3: 99.8489425981873%\n",
      "Test accuracy on previous task 0: 99.66903073286052%\n",
      "Test accuracy on previous task 1: 43.780607247796276%\n",
      "Test accuracy on previous task 2: 82.23052294557097%\n",
      "Test accuracy on previous task 3: 99.8489425981873%\n",
      "Training on task 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c640a943b484c9c896a327b3bdbdb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 4:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 4: 99.3948562783661%\n",
      "Test accuracy on previous task 0: 93.61702127659575%\n",
      "Test accuracy on previous task 1: 38.00195886385896%\n",
      "Test accuracy on previous task 2: 81.59018143009605%\n",
      "Test accuracy on previous task 3: 89.82880161127895%\n",
      "Test accuracy on previous task 4: 99.3948562783661%\n",
      "Accuracies saved to out/experiments/ewc_disc_s_mnist_lambda_ewc_5000/final_accuracies.json\n"
     ]
    }
   ],
   "source": [
    "lambda_ewc = 1  # follow the paper\n",
    "\n",
    "model = MLP().to(device)\n",
    "run_task_ewc(model, f\"ewc_disc_s_mnist_lambda_ewc_{lambda_ewc}\", mnist_train, mnist_test, train_task_ids, test_task_ids, device, epochs=100, batch_size=256, lambda_ewc=lambda_ewc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0813c-ffb3-49a0-b2c8-8c86ef1499e4",
   "metadata": {},
   "source": [
    "## Synaptic Intelligence (SI) for Split MNIST with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ca37246-8539-4814-9ee2-dad57e77a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_task_si(model, log_name, mnist_train, mnist_test, train_task_ids, test_task_ids, device, epochs, batch_size, c_si):\n",
    "    \"\"\"\n",
    "    Trains a given model on MNIST split tasks using the Synaptic Intelligence (SI) method.\n",
    "    \n",
    "    \"\"\"\n",
    "    summary_writer = SummaryWriter(log_dir=os.path.join(\"logs\", log_name, datetime.now().strftime('%Y%m%d_%H%M%S')))\n",
    "    experiment_path = f\"out/experiments/{log_name}\"\n",
    "    os.makedirs(experiment_path, exist_ok=True)  # Ensure output directory exists\n",
    "    accuracies = {}\n",
    "    \n",
    "    # Initialize importance and previous parameters dictionaries\n",
    "    importance = {}\n",
    "    prev_params = {}\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        importance[name] = torch.zeros_like(param, device=device)\n",
    "        prev_params[name] = param.clone().detach()\n",
    "\n",
    "    for task_idx in range(5):\n",
    "        print(f\"Training on task {task_idx}\")\n",
    "        task_dataset = task_subset(mnist_train, train_task_ids, task_idx)\n",
    "        train_loader = DataLoader(task_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_dataset = task_subset(mnist_test, test_task_ids, task_idx)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in tqdm(range(epochs), desc=f\"Training Task {task_idx}\"):\n",
    "            model.train()\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), binarize_y(target, task_idx).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data, task_idx)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Update SI term based on the parameter changes after the step\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.requires_grad:\n",
    "                        delta_param = param.detach() - prev_params[name]\n",
    "                        importance[name] += (param.grad.detach() ** 2) * delta_param if param.grad is not None else 0.0\n",
    "                \n",
    "                # SI regularization\n",
    "                si_term = sum((importance[name] * (param - prev_params[name]) ** 2).sum() for name, param in model.named_parameters())\n",
    "                loss += c_si * si_term\n",
    "\n",
    "            # Update previous parameters after each epoch\n",
    "            prev_params = {name: param.clone().detach() for name, param in model.named_parameters()}\n",
    "\n",
    "            summary_writer.add_scalar(f'Task_{task_idx}/Train_Loss', loss.item(), epoch)\n",
    "            \n",
    "        # Evaluate the model on the current task's test set\n",
    "        test_accuracy = test_model(model, test_loader, device, task_idx)\n",
    "        print(f\"Test accuracy on task {task_idx}: {test_accuracy}%\")\n",
    "        summary_writer.add_scalar(f'Task_{task_idx}/Test_Accuracy', test_accuracy, epoch)\n",
    "        accuracies[f\"TASK {task_idx}\"] = test_accuracy\n",
    "        \n",
    "        # Evaluate the model on all previous tasks' test sets to measure forgetting\n",
    "        for previous_task_idx in range(task_idx + 1):\n",
    "            test_dataset = task_subset(mnist_test, test_task_ids, previous_task_idx)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "            accuracy = test_model(model, test_dataloader, device, previous_task_idx)\n",
    "            print(f\"Test accuracy on previous task {previous_task_idx}: {accuracy}%\")\n",
    "            summary_writer.add_scalar(f\"Cross_Task_Accuracy/task_{task_idx}_on_{previous_task_idx}\", accuracy, global_step=task_idx)\n",
    "            accuracies[f\"TASK {previous_task_idx}\"] = accuracy\n",
    "\n",
    "    # Save accuracies to file\n",
    "    accuracies_file = os.path.join(experiment_path, \"final_accuracies.json\")\n",
    "    with open(accuracies_file, 'w') as f:\n",
    "        json.dump(accuracies, f)\n",
    "    print(f\"Accuracies saved to {accuracies_file}\")\n",
    "\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2aba5757-3b8e-480e-9889-17334ba753b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772b02f0f8fd4215b7979dc7fc75e8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 0:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 99.95271867612293%\n",
      "Test accuracy on previous task 0: 99.95271867612293%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e38aa163cd44261aed225ac75c487cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 1:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 99.60822722820764%\n",
      "Test accuracy on previous task 0: 99.76359338061465%\n",
      "Test accuracy on previous task 1: 99.60822722820764%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5d766dd369459db010f61cb540d518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 2:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 99.89327641408751%\n",
      "Test accuracy on previous task 0: 94.51536643026004%\n",
      "Test accuracy on previous task 1: 81.29285014691479%\n",
      "Test accuracy on previous task 2: 99.89327641408751%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1aa01dbba141428fef814fbacf918b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 3:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 3: 99.8489425981873%\n",
      "Test accuracy on previous task 0: 98.91252955082743%\n",
      "Test accuracy on previous task 1: 38.05093046033301%\n",
      "Test accuracy on previous task 2: 77.00106723585913%\n",
      "Test accuracy on previous task 3: 99.8489425981873%\n",
      "Training on task 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06057f570351464db9ae738e09b4f82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 4:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 4: 99.24357034795764%\n",
      "Test accuracy on previous task 0: 87.94326241134752%\n",
      "Test accuracy on previous task 1: 42.6052889324192%\n",
      "Test accuracy on previous task 2: 84.63180362860192%\n",
      "Test accuracy on previous task 3: 89.72809667673717%\n",
      "Test accuracy on previous task 4: 99.24357034795764%\n",
      "Accuracies saved to out/experiments/si_disc_s_mnist_c_si_1/final_accuracies.json\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 256\n",
    "c_si = 1\n",
    "log_name = f\"si_disc_s_mnist_c_si_{c_si}\" \n",
    "model = MLP().to(device)\n",
    "\n",
    "run_task_si(\n",
    "    model=model,\n",
    "    log_name=log_name,\n",
    "    mnist_train=mnist_train,\n",
    "    mnist_test=mnist_test,\n",
    "    train_task_ids=train_task_ids,\n",
    "    test_task_ids=test_task_ids,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    c_si=c_si\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb0954-85f5-4c66-8b7a-bd94fd9f90d9",
   "metadata": {},
   "source": [
    "## Laplace Propagation Method for Split MNIST Task with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "501ca0a8-227e-4b11-9403-495e63232939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hessian_diag(model, dataloader, device, task_idx):\n",
    "    model.eval()\n",
    "    hessian_diag = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        hessian_diag[name] = torch.zeros_like(param)\n",
    "\n",
    "    for data, target in dataloader:\n",
    "        data, target = data.to(device), binarize_y(target, task_idx).to(device)\n",
    "        model.zero_grad()\n",
    "        output = model(data, task_idx)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        # Set allow_unused=True to handle parameters not used in the graph\n",
    "        grad_params = torch.autograd.grad(loss, model.parameters(), create_graph=True, allow_unused=True)\n",
    "\n",
    "        for grad, (name, param) in zip(grad_params, model.named_parameters()):\n",
    "            if grad is not None:  # Only proceed if the gradient is not None\n",
    "                grad2 = torch.autograd.grad(grad.sum(), param, retain_graph=True, allow_unused=True)[0]\n",
    "                if grad2 is not None:  # Check if the second derivative is not None\n",
    "                    hessian_diag[name] += grad2.data / len(dataloader.dataset)\n",
    "\n",
    "    return hessian_diag\n",
    "\n",
    "\n",
    "def run_task_lp(model, log_name, mnist_train, mnist_test, train_task_ids, test_task_ids, device, epochs, batch_size, gamma_lp):\n",
    "    \"\"\"\n",
    "    Trains a given model on MNIST split tasks using a simplified Laplace Propagation method, approximated with second-order Taylor Expansion.\n",
    "    \n",
    "    \"\"\"\n",
    "    summary_writer = SummaryWriter(log_dir=os.path.join(\"logs\", log_name, datetime.now().strftime('%Y%m%d_%H%M%S')))\n",
    "    experiment_path = f\"out/experiments/{log_name}\"\n",
    "    os.makedirs(experiment_path, exist_ok=True) \n",
    "    accuracies = {}\n",
    "    \n",
    "    # Initialize Hessian approximation (diagonal) and previous parameters\n",
    "    hessian_diag = {}\n",
    "    prev_params = {}\n",
    "\n",
    "    for task_idx in range(5):\n",
    "        print(f\"Training on task {task_idx}\")\n",
    "        task_dataset = task_subset(mnist_train, train_task_ids, task_idx)\n",
    "        train_loader = DataLoader(task_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_dataset = task_subset(mnist_test, test_task_ids, task_idx)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        for epoch in tqdm(range(epochs), desc=f\"Training Task {task_idx}\"):\n",
    "            model.train()\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(device), binarize_y(target, task_idx).to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data, task_idx)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                \n",
    "                if task_idx > 0:\n",
    "                    # Calculate LP regularization term\n",
    "                    lp_loss = 0\n",
    "                    for name, param in model.named_parameters():\n",
    "                        if name in hessian_diag:\n",
    "                            lp_loss += (hessian_diag[name] * (param - prev_params[name]) ** 2).sum()\n",
    "                    loss += gamma_lp * lp_loss\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Update Hessian approximation and previous parameters after each epoch\n",
    "            if task_idx > 0:\n",
    "                hessian_diag = compute_hessian_diag(model, train_loader, device, task_idx)\n",
    "            prev_params = {name: param.clone().detach() for name, param in model.named_parameters()}\n",
    "\n",
    "            summary_writer.add_scalar(f'Task_{task_idx}/Train_Loss', loss.item(), epoch)\n",
    "            \n",
    "        # Evaluate the model on the current task's test set\n",
    "        test_accuracy = test_model(model, test_loader, device, task_idx)\n",
    "        print(f\"Test accuracy on task {task_idx}: {test_accuracy}%\")\n",
    "        summary_writer.add_scalar(f'Task_{task_idx}/Test_Accuracy', test_accuracy, epoch)\n",
    "        accuracies[f\"TASK {task_idx}\"] = test_accuracy\n",
    "\n",
    "        # Evaluate the model on all previous tasks' test sets to measure forgetting\n",
    "        for previous_task_idx in range(task_idx + 1):\n",
    "            test_dataset = task_subset(mnist_test, test_task_ids, previous_task_idx)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "            accuracy = test_model(model, test_dataloader, device, previous_task_idx)\n",
    "            print(f\"Test accuracy on previous task {previous_task_idx}: {accuracy}%\")\n",
    "            summary_writer.add_scalar(f\"Cross_Task_Accuracy/task_{task_idx}_on_{previous_task_idx}\", accuracy, global_step=task_idx)\n",
    "            accuracies[f\"TASK {previous_task_idx}\"] = accuracy\n",
    "\n",
    "    # Save accuracies to file\n",
    "    import json\n",
    "    accuracies_file = os.path.join(experiment_path, \"final_accuracies.json\")\n",
    "    with open(accuracies_file, 'w') as f:\n",
    "        json.dump(accuracies, f)\n",
    "    print(f\"Accuracies saved to {accuracies_file}\")\n",
    "    \n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5d2f3b2-b180-4284-9a1c-bca7a5531644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on task 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dae9c4e24084d1eb936ea3b7255c3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 0:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 0: 99.95271867612293%\n",
      "Test accuracy on previous task 0: 99.95271867612293%\n",
      "Training on task 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0cf2929b5d42b5950ae6187c361429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 1:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 1: 99.4613124387855%\n",
      "Test accuracy on previous task 0: 96.97399527186761%\n",
      "Test accuracy on previous task 1: 99.4613124387855%\n",
      "Training on task 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7beb74cbfa88499db3131ec0214c687f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 2:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 2: 99.73319103521878%\n",
      "Test accuracy on previous task 0: 58.156028368794324%\n",
      "Test accuracy on previous task 1: 82.85994123408423%\n",
      "Test accuracy on previous task 2: 99.73319103521878%\n",
      "Training on task 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a8e2c143744e1c972474bfc3931825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 3:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 3: 99.8489425981873%\n",
      "Test accuracy on previous task 0: 56.92671394799054%\n",
      "Test accuracy on previous task 1: 40.00979431929481%\n",
      "Test accuracy on previous task 2: 82.17716115261473%\n",
      "Test accuracy on previous task 3: 99.8489425981873%\n",
      "Training on task 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0539e8776f46579c843a5e6a30b0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Task 4:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on task 4: 99.29399899142713%\n",
      "Test accuracy on previous task 0: 88.60520094562648%\n",
      "Test accuracy on previous task 1: 41.57688540646425%\n",
      "Test accuracy on previous task 2: 91.40875133404482%\n",
      "Test accuracy on previous task 3: 93.20241691842901%\n",
      "Test accuracy on previous task 4: 99.29399899142713%\n",
      "Accuracies saved to out/experiments/lp_s_MNIST_gamma_lp_0.05/final_accuracies.json\n"
     ]
    }
   ],
   "source": [
    "epochs = 100 \n",
    "batch_size = 256 \n",
    "gamma_lp = 0.05\n",
    "log_name = f\"lp_s_MNIST_gamma_lp_{gamma_lp}\" \n",
    "\n",
    "model = MLP().to(device)\n",
    "\n",
    "run_task_lp(\n",
    "    model=model,\n",
    "    log_name=log_name,\n",
    "    mnist_train=mnist_train,\n",
    "    mnist_test=mnist_test,\n",
    "    train_task_ids=train_task_ids,\n",
    "    test_task_ids=test_task_ids,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    gamma_lp=gamma_lp\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
